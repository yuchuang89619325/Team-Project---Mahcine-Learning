{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4cf19ae-0fb6-4c70-83c3-1ac2ac0f91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras import layers, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b889a7-0d97-431f-9070-ac7a3a6bcdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data Here\n",
    "X = np.load('data_train.npy')\n",
    "Y = np.load('t_train_cor_formatted.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4da88d8-d7e9-4f30-a306-35c98c8be0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_load, train_load):\n",
    "    '''\n",
    "    Data Preprocessing\n",
    "    '''\n",
    "    # Load data\n",
    "    X_early = data_load\n",
    "    t_early = train_load\n",
    "    \n",
    "    # Reshape data\n",
    "    D = 50\n",
    "    X_early = np.array([cv2.resize(x.reshape(300,300), (D,D)).reshape(D*D) \n",
    "    for x in np.transpose (X_early) ])\n",
    "\n",
    "    # Cut out the flattens (-2) and unknown (-1)\n",
    "    X_train = np.delete(np.transpose(X_early), np.where(t_early < 0), axis=1)\n",
    "    t_train = np.delete(t_early, np.where(t_early < 0))\n",
    "    \n",
    "    # Partition the training and test data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_train.T, t_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Reshape data for inputing into model\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], D, D))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], D, D))\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Model Creation\n",
    "    '''\n",
    "    # Model & data parameters\n",
    "    num_classes = 10\n",
    "    variable_learning_rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor = 0.2, patience = 2)\n",
    "    tf.random.set_seed(2)\n",
    "    model = Sequential([\n",
    "        keras.Input(shape=(D, D, 1)),\n",
    "\n",
    "        # Layer 1\n",
    "        layers.Conv2D(filters = 32, kernel_size = 5, strides = 1, activation = 'relu', input_shape = (D, D, 1), kernel_regularizer=regularizers.l2(0.0005)),\n",
    "        # Layer 2\n",
    "        layers.Conv2D(filters = 32, kernel_size = 5, strides = 1, use_bias=False),\n",
    "        # Layer 3\n",
    "        layers.BatchNormalization(),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size = 2, strides = 2),\n",
    "        layers.Dropout(0.25),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        # Layer 4\n",
    "        layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, activation = 'relu', kernel_regularizer=regularizers.l2(0.0005)),\n",
    "        # Layer 5\n",
    "        layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, use_bias=False),\n",
    "        # Layer 6\n",
    "        layers.BatchNormalization(),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size = 2, strides = 2),\n",
    "        layers.Dropout(0.25),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        # Layer 7\n",
    "        layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, activation = 'relu', kernel_regularizer=regularizers.l2(0.0005)),\n",
    "        # Layer 8\n",
    "        layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, use_bias=False),\n",
    "        # Layer 9\n",
    "        layers.BatchNormalization(),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size = 2, strides = 2),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        # Layer 10\n",
    "        layers.Dense(units = 256, use_bias=False),\n",
    "        # Layer 11\n",
    "        layers.BatchNormalization(),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        layers.Activation(\"relu\"),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        # Layer 12\n",
    "        layers.Dense(units = 128, use_bias=False),\n",
    "        # Layer 13\n",
    "        layers.BatchNormalization(),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        layers.Activation(\"relu\"),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        # Layer 14\n",
    "        layers.Dense(units = 84, use_bias=False),\n",
    "        # Layer 15\n",
    "        layers.BatchNormalization(),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.Dropout(0.25),\n",
    "        # — — — — — — — — — — — — — — — — #\n",
    "        # Output\n",
    "        layers.Dense(units = 10, activation = 'softmax')\n",
    "        ])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    '''\n",
    "    Model Compilation\n",
    "    '''\n",
    "    batch_size = 32\n",
    "    epochs = 30\n",
    "\n",
    "    adamopt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Model Training\n",
    "    '''\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, callbacks=[variable_learning_rate], epochs=epochs, validation_split=0.3)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Model Evaluation\n",
    "    '''\n",
    "    print('Model Evaluation:')\n",
    "    model.evaluate(x_train,y_train)\n",
    "    model.evaluate(x_test,y_test)\n",
    "    \n",
    "    '''\n",
    "    Save Model\n",
    "    '''\n",
    "    model.save(\"teaml_final_test_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15cd3bf-b884-49af-9917-f57f5b487ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 21:22:06.694665: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-07 21:22:07.214227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79111 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:87:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 46, 32)        832       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 42, 42, 32)        25600     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 42, 42, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 42, 42, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 21, 21, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 21, 21, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 19, 19, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 17, 17, 64)        36864     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 17, 17, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 17, 17, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 128)         147456    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131072    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32768     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 84)                10752     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 84)               336       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 84)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 481,314\n",
      "Trainable params: 479,930\n",
      "Non-trainable params: 1,384\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 21:22:09.468353: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2022-12-07 21:22:10.311934: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2022-12-07 21:22:10.389191: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-12-07 21:22:11.297196: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 5s 7ms/step - loss: 2.0405 - accuracy: 0.3198 - val_loss: 1.5263 - val_accuracy: 0.5183 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 1.1215 - accuracy: 0.6710 - val_loss: 1.3427 - val_accuracy: 0.5947 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.8658 - accuracy: 0.7411 - val_loss: 1.3695 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.7480 - accuracy: 0.7830 - val_loss: 1.1188 - val_accuracy: 0.6860 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.6687 - accuracy: 0.8021 - val_loss: 1.5844 - val_accuracy: 0.5651 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.6097 - accuracy: 0.8262 - val_loss: 0.6863 - val_accuracy: 0.7896 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.5596 - accuracy: 0.8427 - val_loss: 1.0567 - val_accuracy: 0.6617 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.5524 - accuracy: 0.8491 - val_loss: 0.5221 - val_accuracy: 0.8500 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.5082 - accuracy: 0.8556 - val_loss: 0.6916 - val_accuracy: 0.7882 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.4817 - accuracy: 0.8568 - val_loss: 0.4982 - val_accuracy: 0.8655 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.4516 - accuracy: 0.8746 - val_loss: 0.5267 - val_accuracy: 0.8472 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.4328 - accuracy: 0.8827 - val_loss: 0.7136 - val_accuracy: 0.7887 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.3583 - accuracy: 0.9056 - val_loss: 0.3929 - val_accuracy: 0.8969 - lr: 2.0000e-04\n",
      "Epoch 14/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.3228 - accuracy: 0.9144 - val_loss: 0.3800 - val_accuracy: 0.9002 - lr: 2.0000e-04\n",
      "Epoch 15/30\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 0.3184 - accuracy: 0.9209 - val_loss: 0.3621 - val_accuracy: 0.9053 - lr: 2.0000e-04\n",
      "Epoch 16/30\n",
      "156/156 [==============================] - 1s 5ms/step - loss: 0.3042 - accuracy: 0.9233 - val_loss: 0.3853 - val_accuracy: 0.9016 - lr: 2.0000e-04\n",
      "Epoch 17/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2928 - accuracy: 0.9261 - val_loss: 0.3841 - val_accuracy: 0.8978 - lr: 2.0000e-04\n",
      "Epoch 18/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2663 - accuracy: 0.9321 - val_loss: 0.3524 - val_accuracy: 0.9114 - lr: 4.0000e-05\n",
      "Epoch 19/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2667 - accuracy: 0.9311 - val_loss: 0.3488 - val_accuracy: 0.9114 - lr: 4.0000e-05\n",
      "Epoch 20/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2642 - accuracy: 0.9359 - val_loss: 0.3486 - val_accuracy: 0.9114 - lr: 4.0000e-05\n",
      "Epoch 21/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2622 - accuracy: 0.9377 - val_loss: 0.3477 - val_accuracy: 0.9114 - lr: 4.0000e-05\n",
      "Epoch 22/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2558 - accuracy: 0.9343 - val_loss: 0.3489 - val_accuracy: 0.9091 - lr: 4.0000e-05\n",
      "Epoch 23/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2495 - accuracy: 0.9387 - val_loss: 0.3510 - val_accuracy: 0.9100 - lr: 4.0000e-05\n",
      "Epoch 24/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2519 - accuracy: 0.9345 - val_loss: 0.3506 - val_accuracy: 0.9091 - lr: 8.0000e-06\n",
      "Epoch 25/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2421 - accuracy: 0.9393 - val_loss: 0.3491 - val_accuracy: 0.9105 - lr: 8.0000e-06\n",
      "Epoch 26/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2495 - accuracy: 0.9379 - val_loss: 0.3488 - val_accuracy: 0.9110 - lr: 1.6000e-06\n",
      "Epoch 27/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2445 - accuracy: 0.9413 - val_loss: 0.3490 - val_accuracy: 0.9114 - lr: 1.6000e-06\n",
      "Epoch 28/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2463 - accuracy: 0.9383 - val_loss: 0.3486 - val_accuracy: 0.9105 - lr: 3.2000e-07\n",
      "Epoch 29/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2451 - accuracy: 0.9387 - val_loss: 0.3490 - val_accuracy: 0.9100 - lr: 3.2000e-07\n",
      "Epoch 30/30\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.2543 - accuracy: 0.9339 - val_loss: 0.3491 - val_accuracy: 0.9105 - lr: 6.4000e-08\n",
      "Model Evaluation:\n",
      "223/223 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9511\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.9184\n"
     ]
    }
   ],
   "source": [
    "train(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5879d3-debc-453d-869c-02bceef24f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
